{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SarcasmDetection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaipak/ClassificationCompetition/blob/main/nbs/SarcasmDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXov15HyzCwN"
      },
      "source": [
        "# Set Up Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iERC9lNXidY3"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M7Jl-qqH385"
      },
      "source": [
        "# Set Paths for Google Drive\n",
        "source_folder = '/content/drive/My Drive/Data'\n",
        "destination_folder = '/content/drive/My Drive/Model'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q--JmjG99x_n"
      },
      "source": [
        "# Load Libraries\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import torch\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ScFgNKqIK-y"
      },
      "source": [
        "# Make Sure Transformers Library Is Installed\n",
        "! pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xoj82dtIgoA"
      },
      "source": [
        "# Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XUzzXI1E5A3"
      },
      "source": [
        "# Function to Preprocess Data\n",
        "def PreprocessData(method='response only'):\n",
        "  '''\n",
        "  The method argument can take these possible values:\n",
        "    'response only' = only use response for fitting model\n",
        "    'context only' = only use context for fitting model\n",
        "    'response + context' = concatenate response to context\n",
        "    'context + response' = concatenate context to response\n",
        "  '''\n",
        "\n",
        "  # Read In Train\n",
        "  df = pd.read_json('/content/drive/My Drive/Data/train.jsonl', lines=True, encoding = sys.getdefaultencoding())\n",
        "\n",
        "  # Read In Data For Submission\n",
        "  df_sub = pd.read_json('/content/drive/My Drive/Data/test.jsonl', lines=True, encoding = sys.getdefaultencoding())\n",
        "\n",
        "  # Convert Lables to Integers\n",
        "  df['label'] = (df['label'] == 'SARCASM').astype('int')\n",
        "\n",
        "  # Prepare text Column Based on Method\n",
        "  if method == 'response only':\n",
        "    # Training\n",
        "    df['text'] = df['response']\n",
        "    # Submission\n",
        "    df_sub['text'] = df_sub['response']\n",
        "  \n",
        "  if method == 'context only':\n",
        "    # Training - Concatenate All List Strings in Context Column\n",
        "    df['text'] = df['context'].str.join(\"\") \n",
        "    # Submission - Concatenate All List Strings in Context Column\n",
        "    df_sub['text'] = df_sub['context'].str.join(\"\") \n",
        "\n",
        "  if method == 'response + context':\n",
        "    # Training - Concatenate All List Strings in Context Column\n",
        "    df['context'] = df['context'].str.join(\"\")\n",
        "    # Submission - Concatenate All List Strings in Context Column\n",
        "    df_sub['context'] = df_sub['context'].str.join(\"\")\n",
        "\n",
        "    # Training - Concatenate Respons and Context\n",
        "    df['text'] = df['response'] + df['context']\n",
        "    # Submission - Concatenate Respons and Context\n",
        "    df_sub['text'] = df_sub['response'] + df_sub['context']\n",
        "\n",
        "  if method == 'context + response':\n",
        "    # Training - Concatenate All List Strings in Context Column\n",
        "    df['context'] = df['context'].str.join(\"\")\n",
        "    # Submission - Concatenate All List Strings in Context Column\n",
        "    df_sub['context'] = df_sub['context'].str.join(\"\")\n",
        "\n",
        "    # Training - Concatenate Respons and Context\n",
        "    df['text'] = df['context'] + df['response'] \n",
        "     # Submission - Concatenate Respons and Context\n",
        "    df_sub['text'] = df_sub['context'] + df_sub['response'] \n",
        "    \n",
        "\n",
        "  # Add Bunk Label For Submission\n",
        "  df_sub['id'] = 1\n",
        "  df_sub = df_sub.rename(columns={\"id\": \"label\"})\n",
        "\n",
        "  # Create Dataframes with Only Label and Text Columns\n",
        "  df_processed = df[['label','text']]\n",
        "  df_sub_processed = df_sub[['label','text']]\n",
        "\n",
        "  # Print Dataframe\n",
        "  print(df_processed.head())\n",
        "\n",
        "  # Split into Train and Validate\n",
        "  df_train, df_validate = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "  # Split into Validate and Test\n",
        "  df_validate, df_test = train_test_split(df_validate, test_size=0.5, random_state=42)\n",
        "\n",
        "  # Write Train as CSV\n",
        "  df_train.to_csv('/content/drive/My Drive/Data/train.csv', index=False, encoding = sys.getdefaultencoding())  \n",
        "\n",
        "  # Write Validate as CSV\n",
        "  df_validate.to_csv('/content/drive/My Drive/Data/validate.csv', index=False, encoding = sys.getdefaultencoding())\n",
        "\n",
        "  # Write Test as CSV\n",
        "  df_test.to_csv('/content/drive/My Drive/Data/test.csv', index=False, encoding = sys.getdefaultencoding())\n",
        "\n",
        "  # Write Submission as CSV\n",
        "  df_sub.to_csv('/content/drive/My Drive/Data/sub.csv', index=False, encoding = sys.getdefaultencoding())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_DdMLN9yPw"
      },
      "source": [
        "# More Potential Cleaning Steps\n",
        "\n",
        "# Join List of Context Strings into Single String\n",
        "#df['context'] = df['context'].str.join(\"\") \n",
        "\n",
        "# Concatenate Response and Context\n",
        "#df['response'] = df['context'] + df['response'] \n",
        "\n",
        "# Remove @USER String and Double Space\n",
        "#df['response'] = df.response.str.replace('@USER', '').replace('  ',' ')\n",
        "\n",
        "# Remove White Space at Beggining and End\n",
        "#df['response'] = df.response.str.strip()\n",
        "\n",
        "# Get Only Last 512 Characters\n",
        "#df['response'] = df['response'].str[-512:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkxWNsUSLHTH"
      },
      "source": [
        "# Preprocess Data\n",
        "PreprocessData(method='response + context')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUZuVX1cZr_n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7HvsbKvKqT4"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeEq7UPEzTML"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RQ0Tei7zXX7"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdTe4Xwz1PmG"
      },
      "source": [
        "# Model parameter\n",
        "MAX_SEQ_LEN = 128\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
        "\n",
        "# Fields\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
        "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True, fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
        "#fields = [('context', text_field), ('label', label_field), ('response', text_field)]\n",
        "fields = [('label', label_field), ('text', text_field)]\n",
        "\n",
        "# TabularDataset\n",
        "train, valid, test = TabularDataset.splits(path=source_folder, train='train.csv', validation='validate.csv', test='test.csv', format='CSV', fields=fields, skip_header=True)\n",
        "\n",
        "# Iterators\n",
        "train_iter = BucketIterator(train, batch_size=8, sort_key=lambda x: len(x.text), device=device, train=True, sort=True, sort_within_batch=True)\n",
        "valid_iter = BucketIterator(valid, batch_size=8, sort_key=lambda x: len(x.text), device=device, train=True, sort=True, sort_within_batch=True)\n",
        "test_iter = Iterator(test, batch_size=8, device=device, train=False, shuffle=False, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVN9thxI0O99"
      },
      "source": [
        "class BERT(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "\n",
        "        options_name = \"bert-base-uncased\"\n",
        "        self.encoder = BertForSequenceClassification.from_pretrained(options_name)\n",
        "\n",
        "    def forward(self, text, label):\n",
        "        loss, text_fea = self.encoder(text, labels=label)[:2]\n",
        "\n",
        "        return loss, text_fea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PYwY1oFhk67"
      },
      "source": [
        "# Save and Load Functions\n",
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "def load_checkpoint(load_path, model):\n",
        "    \n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']\n",
        "\n",
        "\n",
        "def save_metrics(save_path, train_loss_list, valid_loss_list, global_steps_list):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'train_loss_list': train_loss_list,\n",
        "                  'valid_loss_list': valid_loss_list,\n",
        "                  'global_steps_list': global_steps_list}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "\n",
        "\n",
        "def load_metrics(load_path):\n",
        "\n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7-_6RORhmEr"
      },
      "source": [
        "# Training Function\n",
        "\n",
        "def train(model,\n",
        "          optimizer,\n",
        "          criterion = nn.BCELoss(),\n",
        "          train_loader = train_iter,\n",
        "          valid_loader = valid_iter,\n",
        "          num_epochs = 15,\n",
        "          eval_every = len(train_iter) // 2,\n",
        "          file_path = destination_folder,\n",
        "          best_valid_loss = float(\"Inf\")):\n",
        "    \n",
        "    # initialize running values\n",
        "    running_loss = 0.0\n",
        "    valid_running_loss = 0.0\n",
        "    global_step = 0\n",
        "    train_loss_list = []\n",
        "    valid_loss_list = []\n",
        "    global_steps_list = []\n",
        "\n",
        "    # training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for (label, text), _ in train_loader:\n",
        "            label = label.type(torch.LongTensor)           \n",
        "            label = label.to(device)\n",
        "            text = text.type(torch.LongTensor)  \n",
        "            text = text.to(device)\n",
        "            output = model(text, label)\n",
        "            loss, _ = output\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update running values\n",
        "            running_loss += loss.item()\n",
        "            global_step += 1\n",
        "\n",
        "            # evaluation step\n",
        "            if global_step % eval_every == 0:\n",
        "                model.eval()\n",
        "                with torch.no_grad():                    \n",
        "\n",
        "                    # validation loop\n",
        "                    for (label, text), _ in valid_loader:\n",
        "                        \n",
        "                        label = label.type(torch.LongTensor)           \n",
        "                        label = label.to(device)\n",
        "                        text = text.type(torch.LongTensor)  \n",
        "                        text = text.to(device)\n",
        "                        output = model(text, label)\n",
        "                        loss, _ = output\n",
        "                        \n",
        "                        valid_running_loss += loss.item()\n",
        "\n",
        "                # evaluation\n",
        "                average_train_loss = running_loss / eval_every\n",
        "                average_valid_loss = valid_running_loss / len(valid_loader)\n",
        "                train_loss_list.append(average_train_loss)\n",
        "                valid_loss_list.append(average_valid_loss)\n",
        "                global_steps_list.append(global_step)\n",
        "\n",
        "                # resetting running values\n",
        "                running_loss = 0.0                \n",
        "                valid_running_loss = 0.0\n",
        "                model.train()\n",
        "\n",
        "                # print progress\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
        "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_loader),\n",
        "                              average_train_loss, average_valid_loss))\n",
        "                \n",
        "                # checkpoint\n",
        "                if best_valid_loss > average_valid_loss:\n",
        "                    best_valid_loss = average_valid_loss\n",
        "                    save_checkpoint(file_path + '/' + 'model.pt', model, best_valid_loss)\n",
        "                    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    \n",
        "    save_metrics(file_path + '/' + 'metrics.pt', train_loss_list, valid_loss_list, global_steps_list)\n",
        "    print('Finished Training!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtiOx8vnhmea"
      },
      "source": [
        "# Instantiate \n",
        "model = BERT().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=8e-7)\n",
        "\n",
        "train(model=model, optimizer=optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcJHlGC8hw1K"
      },
      "source": [
        "train_loss_list, valid_loss_list, global_steps_list = load_metrics(destination_folder + '/metrics.pt')\n",
        "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
        "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
        "plt.xlabel('Global Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llqTEnRyKvKU"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6uMC1SXhxn6"
      },
      "source": [
        "# Evaluation Function\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (label, text), _ in test_loader:\n",
        "\n",
        "                label = label.type(torch.LongTensor)           \n",
        "                label = label.to(device)\n",
        "                text = text.type(torch.LongTensor)  \n",
        "                text = text.to(device)\n",
        "                output = model(text, label)\n",
        "\n",
        "                _, output = output\n",
        "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "                y_true.extend(label.tolist())\n",
        "    \n",
        "    print('Classification Report:')\n",
        "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "\n",
        "    ax.xaxis.set_ticklabels(['SARCASM', 'NOT_SARCASM'])\n",
        "    ax.yaxis.set_ticklabels(['SARCASM', 'NOT_SARCASM'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHA9mOxFh0ey"
      },
      "source": [
        "# Instantiate Model\n",
        "best_model = BERT().to(device)\n",
        "\n",
        "# Load Best Model Params\n",
        "load_checkpoint(destination_folder + '/model.pt', best_model)\n",
        "\n",
        "# Get Predictions\n",
        "evaluate(best_model, test_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmQVfO1BK0Zc"
      },
      "source": [
        "# Run Predictions For Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbT0V9DA7Wsh"
      },
      "source": [
        "# Model parameter\n",
        "MAX_SEQ_LEN = 128\n",
        "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
        "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
        "\n",
        "# Fields\n",
        "label_field = Field(sequential=False, use_vocab=False, batch_first=True, dtype=torch.float)\n",
        "text_field = Field(use_vocab=False, tokenize=tokenizer.encode, lower=False, include_lengths=False, batch_first=True, fix_length=MAX_SEQ_LEN, pad_token=PAD_INDEX, unk_token=UNK_INDEX)\n",
        "fields = [('label', label_field), ('text', text_field)]\n",
        "\n",
        "# TabularDataset\n",
        "train, valid, sub = TabularDataset.splits(path=source_folder, train='train.csv', validation='validate.csv', test='sub.csv', format='CSV', fields=fields, skip_header=True)\n",
        "\n",
        "# Iterators\n",
        "train_iter = BucketIterator(train, batch_size=8, sort_key=lambda x: len(x.text), device=device, train=True, sort=True, sort_within_batch=True)\n",
        "valid_iter = BucketIterator(valid, batch_size=8, sort_key=lambda x: len(x.text), device=device, train=True, sort=True, sort_within_batch=True)\n",
        "sub_iter = Iterator(sub, batch_size=8, device=device, train=False, shuffle=False, sort=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpXATdfkBcwB"
      },
      "source": [
        "# Predict Function\n",
        "def predict(model, sub_loader):\n",
        "    y_pred = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (label, text), _ in sub_loader:\n",
        "                label = label.type(torch.LongTensor)           \n",
        "                label = label.to(device)\n",
        "                text = text.type(torch.LongTensor)  \n",
        "                text = text.to(device)\n",
        "                output = model(text, label)\n",
        "\n",
        "                _, output = output\n",
        "                y_pred.extend(torch.argmax(output, 1).tolist())\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWzXDIS-Brfu"
      },
      "source": [
        "# Instantiate Model\n",
        "best_model = BERT().to(device)\n",
        "\n",
        "# Load Best Model Params\n",
        "load_checkpoint(destination_folder + '/model.pt', best_model)\n",
        "\n",
        "# Get Predictions\n",
        "y_pred = predict(best_model, sub_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-sqKxkTCjo5"
      },
      "source": [
        "# Create Lists of IDs and Predictions\n",
        "id_list = ['twitter_' + str(x) for x in range(1,1801)]\n",
        "label_list = ['SARCASM' if x == 1 else 'NOT_SARCASM' for x in y_pred] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5YjVSjuJxvD"
      },
      "source": [
        "# Create Dataframe for Submission\n",
        "df_submission = pd.DataFrame(list(zip(id_list, label_list)), columns =['id', 'label']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXXX3O-9KwiZ"
      },
      "source": [
        "df_submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMk2CdZ8LCMx"
      },
      "source": [
        "# Write Out Submission File\n",
        "df_submission.to_csv('/content/drive/My Drive/Data/answer.txt', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkE1RDA0xum5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}